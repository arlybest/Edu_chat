import os
import logging
import streamlit as st
from pinecone import Pinecone
from langchain.vectorstores import Pinecone as PineconeLangChain
from langchain.embeddings import HuggingFaceEmbeddings
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate

st.set_page_config(page_title="Edu_Chat", layout="wide")

# üîπ Configuration des logs
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# üîπ Cl√©s API
PINECONE_API_KEY = "pcsk_53U2S4_H35UkcZBx97Wr6JgdNpjhb6yKHEhr8XHDUFTwUtyQbjHk5AYxmSEPLBf9VHBNzC"
GOOGLE_API_KEY = "AIzaSyAzPkQdUlVtp3iqre6lxMACoPUQNFKlYJg"

# üîπ Initialisation de Pinecone
os.environ["PINECONE_API_KEY"] = PINECONE_API_KEY
pc = Pinecone(api_key=PINECONE_API_KEY)

# üîπ Cr√©ation de l'index Pinecone
INDEX_NAME = "pdf-documents-index-v2"
if INDEX_NAME not in pc.list_indexes().names():
    pc.create_index(name=INDEX_NAME, dimension=1536, metric="cosine")

# üîπ Initialisation du mod√®le d'embeddings
embedding_model = HuggingFaceEmbeddings(model_name="intfloat/multilingual-e5-large")

# üîπ Chargement de Pinecone via LangChain
vectorstore = PineconeLangChain.from_existing_index(index_name=INDEX_NAME, embedding=embedding_model)

# üîπ Initialisation du mod√®le LLM (Gemini)
llm = ChatGoogleGenerativeAI(
    model="gemini-1.5-pro",
    google_api_key=GOOGLE_API_KEY,
    temperature=0.5,
    max_tokens=None,
    max_retries=2
)

# üîπ Prompt pour guider les r√©ponses
prompt_template = PromptTemplate(
    input_variables=["context", "question", "history"],
    template="""
    Utilise uniquement les informations suivantes tir√©es des documents pour r√©pondre √† la question de l'utilisateur. Ne fais pas d'hypoth√®ses ou ne r√©ponds pas en dehors du contexte des documents.

    Contexte :
    {context}

    Historique de la conversation :
    {history}

    Question :
    {question}

    R√©ponse :
    """
)

# üîπ Configuration du syst√®me de r√©cup√©ration des informations
retriever = vectorstore.as_retriever(search_kwargs={"k": 10})
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",
    retriever=retriever,
    return_source_documents=True
)

# üîπ Gestion du contexte de conversation
if "conversation_history" not in st.session_state:
    st.session_state.conversation_history = []

def answer_question(question: str) -> str:
    """
    Recherche des documents pertinents et g√©n√®re une r√©ponse avec Gemini.
    """
    try:
        logging.info("üîç Recherche et g√©n√©ration de r√©ponse...")

        # Historique sous forme de texte
        history = "\n".join(st.session_state.conversation_history)

        # Ajouter l'espace r√©serv√© pour le spinner devant l'ic√¥ne du bot
        placeholder = st.empty()  # Placeholder r√©serv√© pour le spinner

        with placeholder:
            with st.spinner('Je r√©fl√©chis...'):
                # G√©n√©ration de la r√©ponse
                result = qa_chain({"query": question, "history": history})
                response = result["result"]
                sources = result.get("source_documents", [])

        # Mise √† jour de l'historique de conversation
        st.session_state.conversation_history.append(f"Question: {question}")
        st.session_state.conversation_history.append(f"R√©ponse: {response}")

        # Log des sources
        if sources:
            logging.info(f"üìú Sources utilis√©es : {[doc.page_content[:300] for doc in sources]}")
        else:
            logging.info("‚ö†Ô∏è Aucun document source trouv√©.")

        # Remplacer le spinner par la r√©ponse g√©n√©r√©e
        placeholder.empty()  # Vide le placeholder pour remplacer le spinner
        return response.strip() if response.strip() else "D√©sol√©, aucune r√©ponse pertinente n'a √©t√© trouv√©e."

    except Exception as e:
        logging.error(f"‚ùå Erreur : {e}")
        return "Une erreur s'est produite. Veuillez r√©essayer."

# üìå Customisation du design (sans toucher au front-end original)
def add_custom_css():
    st.markdown(
        """
        <style>
        body {
            font-family: 'Arial', sans-serif;
            background-color: #f0f6fc;
            color: #1b3b6f;
        }
        .header-title {
            text-align: center;
            font-size: 50px;
            font-weight: bold;
            color: #ffffff;
            padding: 20px;
            background: linear-gradient(135deg, #87CEEB, #00BFFF);
            border-radius: 12px;
        }
        .stSidebar {
            background-color: #87CEEB !important;
            padding: 20px;
            border-radius: 10px;
        }
        .footer {
            text-align: center;
            color: white;
            font-size: 14px;
            padding: 15px;
            margin-top: 30px;
            background: linear-gradient(135deg, #87CEEB, #00BFFF);
            border-radius: 10px;
        }
        .chat-message {
            display: flex;
            align-items: center;
            padding: 5px;
        }
        .bot-avatar {
            width: 30px;
            height: 30px;
            border-radius: 50%;
            background-color: #1b3b6f;
            margin-right: 10px;
            display: inline-block; /* Juste pour s'assurer qu'il est inline */
        }
        .bot-avatar img {
            width: 100%;
            height: 100%;
            border-radius: 50%;
            object-fit: cover;
        }
        </style>
        """, unsafe_allow_html=True
    )

add_custom_css()

st.sidebar.markdown("<div class='stSidebar'>", unsafe_allow_html=True)
st.sidebar.image("pages/sticker.png", use_container_width=True)
st.sidebar.markdown("</div>", unsafe_allow_html=True)

st.markdown("<div class='header-title'>üí¨ Edu Chat - Chatbot</div>", unsafe_allow_html=True)

# üìå D√©marrer la conversation sans message d'initiation du bot
if "messages" not in st.session_state:
    st.session_state.messages = []

# Affichage des messages existants
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        # Ajouter l'avatar du bot pour chaque message
        if message["role"] == "assistant":
            st.markdown(f'<div class="chat-message"><div class="bot-avatar"></div><span>{message["content"]}</span></div>', unsafe_allow_html=True)
        else:
            st.markdown(message["content"])

# üìå Interaction avec l'utilisateur via `st.chat_message`
def on_new_message(message):
    if message:
        # Ajouter la question de l'utilisateur √† l'historique
        st.session_state.messages.append({"role": "user", "content": message})
        
        # G√©n√©rer la r√©ponse avec le mod√®le
        response = answer_question(message)

        # Ajouter la r√©ponse √† l'historique
        st.session_state.messages.append({"role": "assistant", "content": response})

        # R√©afficher la conversation
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                # Ajouter l'avatar du bot pour chaque message
                if message["role"] == "assistant":
                    st.markdown(f'<div class="chat-message"><div class="bot-avatar"></div><span>{message["content"]}</span></div>', unsafe_allow_html=True)
                else:
                    st.markdown(message["content"])

# üìå Placeholder dans la bo√Æte de chat
message = st.chat_input("√âcrire √† Educhat")  # Placeholder chang√© ici

if message:
    on_new_message(message)
